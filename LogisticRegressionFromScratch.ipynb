{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0HDdGnJNWcV"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "\n",
        "def load_dataset():\n",
        "    train_dataset = h5py.File('/content/train_catvnoncat.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File('/content/test_catvnoncat.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "\n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZOEqueScFrS"
      },
      "source": [
        "#Loading the data\n",
        "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRPIG9wld45P"
      },
      "source": [
        "#Practice loading a picture\n",
        "index = 37\n",
        "plt.imshow(train_set_x_orig[index])\n",
        "print(\"y = \" + str(train_set_y[:,index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:,index])].decode(\"utf-8\") +  \"' picture.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3h6LDi8eIaL"
      },
      "source": [
        "m_train = train_set_y.shape[1] #number of training examples\n",
        "m_test = test_set_y.shape[1] #number of test examples\n",
        "num_px = train_set_x_orig.shape[1] #number of pixels in each image\n",
        "\n",
        "print(\"Number of training examples: m_train = \" + str(m_train))\n",
        "print(\"Number of testing examples: m_test = \" + str(m_test))\n",
        "print(\"Height/Width of each image: num_px = \" + str(num_px))\n",
        "print(\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
        "print(\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
        "print(\"train_set_y shape: \" + str(train_set_y.shape))\n",
        "print(\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
        "print(\"test_set_y shape: \" + str(test_set_y.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_SHTdzzeys0"
      },
      "source": [
        "#convert images from each being an array to a single array represented as a column\n",
        "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
        "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
        "\n",
        "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
        "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
        "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
        "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
        "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgY9jxoWh4Zz"
      },
      "source": [
        "#standardize the dataset\n",
        "train_set_x = train_set_x_flatten / 255\n",
        "test_set_x = test_set_x_flatten / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEO6P1r-itzd"
      },
      "source": [
        "#creating sigmoid() function for model prediction\n",
        "def sigmoid(x):\n",
        "  y = 1/(1+np.exp(-x))\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJFLGJyLj9Ek"
      },
      "source": [
        "#intializing model parameters\n",
        "def initialize(size):\n",
        "  w = np.zeros(shape=(size, 1))\n",
        "  b = 0\n",
        "  return w, b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noWrfP5xktXu"
      },
      "source": [
        "def propagate(w, b, X, Y):\n",
        "  m = X. shape[1]\n",
        "\n",
        "  A = sigmoid(np.dot(w.T, X) + b)\n",
        "  cost = (-1/m) * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n",
        "\n",
        "  dw = (1/m) * (np.dot(X, (A-Y).T))\n",
        "  db = (1/m) * (np.sum(A-Y))\n",
        "\n",
        "  grads = {\"dw\": dw,\n",
        "          \"db\": db}\n",
        "\n",
        "  assert(dw.shape == w.shape)\n",
        "  assert(db.dtype == float)\n",
        "  cost = np.squeeze(cost)\n",
        "  assert(cost.shape == ())\n",
        "\n",
        "  return grads, cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPRQRpCSJtdS"
      },
      "source": [
        "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost):\n",
        "  costs = []\n",
        "\n",
        "  for i in range(num_iterations):\n",
        "    grads, cost = propagate(w, b, X, Y)\n",
        "    dw = grads[\"dw\"]\n",
        "    db = grads[\"db\"]\n",
        "    w = w - dw * learning_rate\n",
        "    b = b - db * learning_rate\n",
        "\n",
        "    if i % 100 == 0:\n",
        "      costs.append(cost)\n",
        "    if print_cost and i % 100 == 0:\n",
        "      print(\"Cost after iteration\", i, \": \", cost)\n",
        "\n",
        "    params = {\"w\": w,\n",
        "              \"b\": b}\n",
        "    grads = {\"dw\": dw,\n",
        "             \"db\": b}\n",
        "\n",
        "  return params, grads, costs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50eLDVNMRi71"
      },
      "source": [
        "def predict(w, b, X):\n",
        "  m = X.shape[1]\n",
        "  Y_prediction = np.zeros((1,m))\n",
        "  w = w.reshape(X.shape[0], 1)\n",
        "\n",
        "  A = sigmoid(np.dot(w.T, X) + b)\n",
        "\n",
        "  for i in range(A.shape[1]):\n",
        "    if A[0,i] > 0.5:\n",
        "      Y_prediction[0,i] = 1\n",
        "    else:\n",
        "      Y_prediction[0,i] = 0\n",
        "\n",
        "  assert (Y_prediction.shape == (1, m))\n",
        "\n",
        "  return Y_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fabn-MpZKYTs"
      },
      "source": [
        "print(\"predictions = \" + str(predict(w, b, X)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hR4kprTf5wN"
      },
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, num_iterations, learning_rate, print_cost):\n",
        "  # initialize parameters\n",
        "  w, b = initialize(X_train.shape[0])\n",
        "  # implement gradient descent\n",
        "  params, costs, grads = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
        "  #retrieve parameters\n",
        "  w = params[\"w\"]\n",
        "  b = params[\"b\"]\n",
        "  #calculate\n",
        "  Y_prediction_train = predict(w, b, X_train)\n",
        "  Y_prediction_test = predict(w, b, X_test)\n",
        "  # print results from a dictionary\n",
        "  print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
        "  print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
        "\n",
        "  d = {\"costs\": costs,\n",
        "        \"Y_prediction_test\": Y_prediction_test,\n",
        "        \"Y_prediction_train\" : Y_prediction_train,\n",
        "        \"w\" : w,\n",
        "        \"b\" : b,\n",
        "        \"learning_rate\" : learning_rate,\n",
        "        \"num_iterations\": num_iterations}\n",
        "\n",
        "  return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwxMzKoHPfNa"
      },
      "source": [
        "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}